{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12892091,"sourceType":"datasetVersion","datasetId":8156675}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install indic-nlp-library","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:34.526983Z","iopub.execute_input":"2025-08-29T08:43:34.527237Z","iopub.status.idle":"2025-08-29T08:43:40.321890Z","shell.execute_reply.started":"2025-08-29T08:43:34.527215Z","shell.execute_reply":"2025-08-29T08:43:40.321145Z"}},"outputs":[{"name":"stdout","text":"Collecting indic-nlp-library\n  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\nCollecting sphinx-argparse (from indic-nlp-library)\n  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.2.4)\nCollecting morfessor (from indic-nlp-library)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.4)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\nRequirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->indic-nlp-library) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.6.15)\nDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m685.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\nInstalling collected packages: morfessor, sphinx-argparse, indic-nlp-library\nSuccessfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer\nimport torch\nfrom indicnlp.tokenize import indic_tokenize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:42.522132Z","iopub.execute_input":"2025-08-29T08:43:42.522715Z","iopub.status.idle":"2025-08-29T08:43:50.837830Z","shell.execute_reply.started":"2025-08-29T08:43:42.522682Z","shell.execute_reply":"2025-08-29T08:43:50.837094Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/english-hindi-dataset/Sentence pairs in English-Hindi - 2025-02-11.tsv\",\n                  sep=\"\\t\",header=None,names=[\"SrcSentID\",\"SrcSent\",\"DstSentID\",\"DstSent\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:53.410532Z","iopub.execute_input":"2025-08-29T08:43:53.411106Z","iopub.status.idle":"2025-08-29T08:43:53.496260Z","shell.execute_reply.started":"2025-08-29T08:43:53.411050Z","shell.execute_reply":"2025-08-29T08:43:53.495170Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:54.396487Z","iopub.execute_input":"2025-08-29T08:43:54.397065Z","iopub.status.idle":"2025-08-29T08:43:54.419315Z","shell.execute_reply.started":"2025-08-29T08:43:54.397039Z","shell.execute_reply":"2025-08-29T08:43:54.418521Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   SrcSentID                                  SrcSent  DstSentID  \\\n0       1282                       Muiriel is 20 now.     485968   \n1       1282                       Muiriel is 20 now.    2060319   \n2       1294  Education in this world disappoints me.     485564   \n3       1302                       That won't happen.    2060320   \n4       1308                              I miss you.    2060321   \n\n                                       DstSent  \n0             म्यूरियल अब बीस साल की हो गई है।  \n1                   म्यूरियल अब बीस साल की है।  \n2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n3                              वैसा नहीं होगा।  \n4                 मुझें तुम्हारी याद आ रही है।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSentID</th>\n      <th>SrcSent</th>\n      <th>DstSentID</th>\n      <th>DstSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>485968</td>\n      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>2060319</td>\n      <td>म्यूरियल अब बीस साल की है।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1294</td>\n      <td>Education in this world disappoints me.</td>\n      <td>485564</td>\n      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1302</td>\n      <td>That won't happen.</td>\n      <td>2060320</td>\n      <td>वैसा नहीं होगा।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1308</td>\n      <td>I miss you.</td>\n      <td>2060321</td>\n      <td>मुझें तुम्हारी याद आ रही है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data.drop(labels=[data.columns[0],data.columns[2]],axis=1,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:54.914067Z","iopub.execute_input":"2025-08-29T08:43:54.914792Z","iopub.status.idle":"2025-08-29T08:43:54.925473Z","shell.execute_reply.started":"2025-08-29T08:43:54.914761Z","shell.execute_reply":"2025-08-29T08:43:54.924670Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:55.324607Z","iopub.execute_input":"2025-08-29T08:43:55.324901Z","iopub.status.idle":"2025-08-29T08:43:55.333282Z","shell.execute_reply.started":"2025-08-29T08:43:55.324881Z","shell.execute_reply":"2025-08-29T08:43:55.332631Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                   SrcSent  \\\n0                       Muiriel is 20 now.   \n1                       Muiriel is 20 now.   \n2  Education in this world disappoints me.   \n3                       That won't happen.   \n4                              I miss you.   \n\n                                       DstSent  \n0             म्यूरियल अब बीस साल की हो गई है।  \n1                   म्यूरियल अब बीस साल की है।  \n2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n3                              वैसा नहीं होगा।  \n4                 मुझें तुम्हारी याद आ रही है।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DstSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Muiriel is 20 now.</td>\n      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Muiriel is 20 now.</td>\n      <td>म्यूरियल अब बीस साल की है।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Education in this world disappoints me.</td>\n      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>That won't happen.</td>\n      <td>वैसा नहीं होगा।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I miss you.</td>\n      <td>मुझें तुम्हारी याद आ रही है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"src_sent_tokenizer = AutoTokenizer.from_pretrained(\"google-T5/T5-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:43:58.298884Z","iopub.execute_input":"2025-08-29T08:43:58.299264Z","iopub.status.idle":"2025-08-29T08:44:02.228288Z","shell.execute_reply.started":"2025-08-29T08:43:58.299240Z","shell.execute_reply":"2025-08-29T08:44:02.227479Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a7df50c8c94484b518b5368f727971"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63de7c5e7704a4f84afa36be6f915ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9884c8942764c06abe529ea86a4a856"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data[\"SrcSent\"] = data[\"SrcSent\"].apply(lambda x: src_sent_tokenizer.tokenize(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:02.229542Z","iopub.execute_input":"2025-08-29T08:44:02.229827Z","iopub.status.idle":"2025-08-29T08:44:02.954684Z","shell.execute_reply.started":"2025-08-29T08:44:02.229795Z","shell.execute_reply":"2025-08-29T08:44:02.954111Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:02.955443Z","iopub.execute_input":"2025-08-29T08:44:02.955721Z","iopub.status.idle":"2025-08-29T08:44:02.964244Z","shell.execute_reply.started":"2025-08-29T08:44:02.955697Z","shell.execute_reply":"2025-08-29T08:44:02.963520Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                             SrcSent  \\\n0                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n1                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n2  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n3                    [▁That, ▁won, ', t, ▁happen, .]   \n4                               [▁I, ▁miss, ▁you, .]   \n\n                                       DstSent  \n0             म्यूरियल अब बीस साल की हो गई है।  \n1                   म्यूरियल अब बीस साल की है।  \n2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n3                              वैसा नहीं होगा।  \n4                 मुझें तुम्हारी याद आ रही है।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DstSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>म्यूरियल अब बीस साल की है।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n      <td>वैसा नहीं होगा।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[▁I, ▁miss, ▁you, .]</td>\n      <td>मुझें तुम्हारी याद आ रही है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data[\"DstSent\"] = data[\"DstSent\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:03.931606Z","iopub.execute_input":"2025-08-29T08:44:03.931891Z","iopub.status.idle":"2025-08-29T08:44:04.060268Z","shell.execute_reply.started":"2025-08-29T08:44:03.931871Z","shell.execute_reply":"2025-08-29T08:44:04.059486Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data[\"SrcSent\"] = data[\"SrcSent\"].apply(src_sent_tokenizer.convert_tokens_to_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:05.268801Z","iopub.execute_input":"2025-08-29T08:44:05.269066Z","iopub.status.idle":"2025-08-29T08:44:05.496751Z","shell.execute_reply.started":"2025-08-29T08:44:05.269047Z","shell.execute_reply":"2025-08-29T08:44:05.495899Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"Vs = src_sent_tokenizer.get_vocab()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:08.297208Z","iopub.execute_input":"2025-08-29T08:44:08.297916Z","iopub.status.idle":"2025-08-29T08:44:08.325067Z","shell.execute_reply.started":"2025-08-29T08:44:08.297881Z","shell.execute_reply":"2025-08-29T08:44:08.324301Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:08.936724Z","iopub.execute_input":"2025-08-29T08:44:08.937447Z","iopub.status.idle":"2025-08-29T08:44:08.946079Z","shell.execute_reply.started":"2025-08-29T08:44:08.937421Z","shell.execute_reply":"2025-08-29T08:44:08.945432Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                 SrcSent  \\\n0     [4159, 23, 14018, 19, 460, 230, 5]   \n1     [4159, 23, 14018, 19, 460, 230, 5]   \n2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n3            [466, 751, 31, 17, 1837, 5]   \n4                      [27, 3041, 25, 5]   \n\n                                             DstSent  \n0        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n1                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n2  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n3                              [वैसा, नहीं, होगा, ।]  \n4              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DstSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[466, 751, 31, 17, 1837, 5]</td>\n      <td>[वैसा, नहीं, होगा, ।]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[27, 3041, 25, 5]</td>\n      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"hindi_vocab = set()\n\nfor tokenized_hindi_sent in data[\"DstSent\"]:\n    hindi_vocab.update(tokenized_hindi_sent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:10.466784Z","iopub.execute_input":"2025-08-29T08:44:10.467326Z","iopub.status.idle":"2025-08-29T08:44:10.479811Z","shell.execute_reply.started":"2025-08-29T08:44:10.467303Z","shell.execute_reply":"2025-08-29T08:44:10.479148Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"Vd = dict()\nfor idx, token in enumerate(hindi_vocab):\n    Vd[token] = idx + 3\nVd[\"<PAD>\"] = 0\nVd[\"<SOS>\"] = 1\nVd[\"<EOS>\"] = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:11.921667Z","iopub.execute_input":"2025-08-29T08:44:11.921949Z","iopub.status.idle":"2025-08-29T08:44:11.928955Z","shell.execute_reply.started":"2025-08-29T08:44:11.921923Z","shell.execute_reply":"2025-08-29T08:44:11.928128Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def convert_hindi_tokens_to_ids(hindi_sent):\n    return [Vd[token] for token in hindi_sent]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:13.788751Z","iopub.execute_input":"2025-08-29T08:44:13.789427Z","iopub.status.idle":"2025-08-29T08:44:13.792780Z","shell.execute_reply.started":"2025-08-29T08:44:13.789403Z","shell.execute_reply":"2025-08-29T08:44:13.792157Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"data[\"DstSent\"] = data[\"DstSent\"].apply(lambda x: convert_hindi_tokens_to_ids(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:14.369274Z","iopub.execute_input":"2025-08-29T08:44:14.369570Z","iopub.status.idle":"2025-08-29T08:44:14.392625Z","shell.execute_reply.started":"2025-08-29T08:44:14.369547Z","shell.execute_reply":"2025-08-29T08:44:14.391639Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:16.245472Z","iopub.execute_input":"2025-08-29T08:44:16.245745Z","iopub.status.idle":"2025-08-29T08:44:16.255398Z","shell.execute_reply.started":"2025-08-29T08:44:16.245724Z","shell.execute_reply":"2025-08-29T08:44:16.254623Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                 SrcSent  \\\n0     [4159, 23, 14018, 19, 460, 230, 5]   \n1     [4159, 23, 14018, 19, 460, 230, 5]   \n2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n3            [466, 751, 31, 17, 1837, 5]   \n4                      [27, 3041, 25, 5]   \n\n                                             DstSent  \n0  [2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...  \n1          [2859, 5060, 3484, 2303, 5172, 396, 5367]  \n2  [3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...  \n3                             [277, 2000, 548, 5367]  \n4           [1259, 4200, 720, 4769, 5397, 396, 5367]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DstSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 396, 5367]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n      <td>[3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[466, 751, 31, 17, 1837, 5]</td>\n      <td>[277, 2000, 548, 5367]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[27, 3041, 25, 5]</td>\n      <td>[1259, 4200, 720, 4769, 5397, 396, 5367]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def insert_sos_token_id(hindi_sent_token_ids):\n    return [1] + hindi_sent_token_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:16.641757Z","iopub.execute_input":"2025-08-29T08:44:16.642029Z","iopub.status.idle":"2025-08-29T08:44:16.645627Z","shell.execute_reply.started":"2025-08-29T08:44:16.642007Z","shell.execute_reply":"2025-08-29T08:44:16.644963Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data[\"DstSentInput\"] = data[\"DstSent\"].apply(lambda x: insert_sos_token_id(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:19.043549Z","iopub.execute_input":"2025-08-29T08:44:19.043823Z","iopub.status.idle":"2025-08-29T08:44:19.055405Z","shell.execute_reply.started":"2025-08-29T08:44:19.043805Z","shell.execute_reply":"2025-08-29T08:44:19.054740Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def insert_eos_token_id(hindi_sent_token_ids):\n    return hindi_sent_token_ids + [2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:19.387674Z","iopub.execute_input":"2025-08-29T08:44:19.387938Z","iopub.status.idle":"2025-08-29T08:44:19.391672Z","shell.execute_reply.started":"2025-08-29T08:44:19.387916Z","shell.execute_reply":"2025-08-29T08:44:19.390978Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"data[\"DstSentLabel\"] = data[\"DstSent\"].apply(lambda x: insert_eos_token_id(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:21.675423Z","iopub.execute_input":"2025-08-29T08:44:21.675662Z","iopub.status.idle":"2025-08-29T08:44:21.687918Z","shell.execute_reply.started":"2025-08-29T08:44:21.675646Z","shell.execute_reply":"2025-08-29T08:44:21.687155Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:22.114199Z","iopub.execute_input":"2025-08-29T08:44:22.114467Z","iopub.status.idle":"2025-08-29T08:44:22.127283Z","shell.execute_reply.started":"2025-08-29T08:44:22.114447Z","shell.execute_reply":"2025-08-29T08:44:22.126554Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                 SrcSent  \\\n0     [4159, 23, 14018, 19, 460, 230, 5]   \n1     [4159, 23, 14018, 19, 460, 230, 5]   \n2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n3            [466, 751, 31, 17, 1837, 5]   \n4                      [27, 3041, 25, 5]   \n\n                                             DstSent  \\\n0  [2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...   \n1          [2859, 5060, 3484, 2303, 5172, 396, 5367]   \n2  [3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...   \n3                             [277, 2000, 548, 5367]   \n4           [1259, 4200, 720, 4769, 5397, 396, 5367]   \n\n                                        DstSentInput  \\\n0  [1, 2859, 5060, 3484, 2303, 5172, 2540, 6820, ...   \n1       [1, 2859, 5060, 3484, 2303, 5172, 396, 5367]   \n2  [1, 3439, 4062, 1340, 6474, 3320, 3042, 2316, ...   \n3                          [1, 277, 2000, 548, 5367]   \n4        [1, 1259, 4200, 720, 4769, 5397, 396, 5367]   \n\n                                        DstSentLabel  \n0  [2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...  \n1       [2859, 5060, 3484, 2303, 5172, 396, 5367, 2]  \n2  [3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...  \n3                          [277, 2000, 548, 5367, 2]  \n4        [1259, 4200, 720, 4769, 5397, 396, 5367, 2]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DstSent</th>\n      <th>DstSentInput</th>\n      <th>DstSentLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...</td>\n      <td>[1, 2859, 5060, 3484, 2303, 5172, 2540, 6820, ...</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 2540, 6820, 396...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 396, 5367]</td>\n      <td>[1, 2859, 5060, 3484, 2303, 5172, 396, 5367]</td>\n      <td>[2859, 5060, 3484, 2303, 5172, 396, 5367, 2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n      <td>[3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...</td>\n      <td>[1, 3439, 4062, 1340, 6474, 3320, 3042, 2316, ...</td>\n      <td>[3439, 4062, 1340, 6474, 3320, 3042, 2316, 586...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[466, 751, 31, 17, 1837, 5]</td>\n      <td>[277, 2000, 548, 5367]</td>\n      <td>[1, 277, 2000, 548, 5367]</td>\n      <td>[277, 2000, 548, 5367, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[27, 3041, 25, 5]</td>\n      <td>[1259, 4200, 720, 4769, 5397, 396, 5367]</td>\n      <td>[1, 1259, 4200, 720, 4769, 5397, 396, 5367]</td>\n      <td>[1259, 4200, 720, 4769, 5397, 396, 5367, 2]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"data.drop(labels=[data.columns[1]],axis=1,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:24.268484Z","iopub.execute_input":"2025-08-29T08:44:24.268755Z","iopub.status.idle":"2025-08-29T08:44:24.274509Z","shell.execute_reply.started":"2025-08-29T08:44:24.268735Z","shell.execute_reply":"2025-08-29T08:44:24.273850Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"X = list(data[\"SrcSent\"])\nY_input = list(data[\"DstSentInput\"])\nY_label = list(data[\"DstSentLabel\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:24.657915Z","iopub.execute_input":"2025-08-29T08:44:24.658229Z","iopub.status.idle":"2025-08-29T08:44:24.665714Z","shell.execute_reply.started":"2025-08-29T08:44:24.658205Z","shell.execute_reply":"2025-08-29T08:44:24.664846Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"X_tensor = [torch.tensor(tokenized_eng_sent_ids) for tokenized_eng_sent_ids in X]\nY_input_tensor = [torch.tensor(tokenized_hin_sent_ids) for tokenized_hin_sent_ids in Y_input]\nY_label_tensor = [torch.tensor(tokenized_hin_sent_ids) for tokenized_hin_sent_ids in Y_label]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:27.720509Z","iopub.execute_input":"2025-08-29T08:44:27.721006Z","iopub.status.idle":"2025-08-29T08:44:27.988743Z","shell.execute_reply.started":"2025-08-29T08:44:27.720985Z","shell.execute_reply":"2025-08-29T08:44:27.988126Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\nY_padded_input = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\nY_padded_label = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:28.440279Z","iopub.execute_input":"2025-08-29T08:44:28.440532Z","iopub.status.idle":"2025-08-29T08:44:28.639438Z","shell.execute_reply.started":"2025-08-29T08:44:28.440516Z","shell.execute_reply":"2025-08-29T08:44:28.638814Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"Ns = X_padded.shape[1]\nNd = Y_padded_label.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:31.105601Z","iopub.execute_input":"2025-08-29T08:44:31.105882Z","iopub.status.idle":"2025-08-29T08:44:31.109914Z","shell.execute_reply.started":"2025-08-29T08:44:31.105862Z","shell.execute_reply":"2025-08-29T08:44:31.109047Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class Encoder(torch.nn.Module):\n\n    def __init__(self,src_lang_vocab_size,word_embedding_dim):\n        super(Encoder,self).__init__()\n        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=src_lang_vocab_size,\n                                                       embedding_dim=word_embedding_dim)\n        self.second_lstm_layer = torch.nn.LSTM(input_size=word_embedding_dim,\n                                               hidden_size=word_embedding_dim,\n                                              batch_first=True)\n\n    def forward(self,X_padded_mini_batch):\n\n        first_embedding_layer_out = self.first_embedding_layer(X_padded_mini_batch)\n        encoder_output, (final_encoder_output,final_cell_state) = self.second_lstm_layer(first_embedding_layer_out)\n\n        return encoder_output, (final_encoder_output,final_cell_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:36.237035Z","iopub.execute_input":"2025-08-29T08:44:36.237354Z","iopub.status.idle":"2025-08-29T08:44:36.244841Z","shell.execute_reply.started":"2025-08-29T08:44:36.237332Z","shell.execute_reply":"2025-08-29T08:44:36.243880Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"class Decoder(torch.nn.Module):\n\n    def __init__(self,dst_lang_vocab_size,word_embedding_dim):\n        super(Decoder,self).__init__()\n\n        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=dst_lang_vocab_size,\n                                                       embedding_dim=word_embedding_dim)\n        self.second_lstm_layer = torch.nn.LSTM(input_size=word_embedding_dim,\n                                               hidden_size=word_embedding_dim,\n                                              batch_first=True)\n        self.prediction_layer = torch.nn.Linear(in_features=word_embedding_dim,out_features=dst_lang_vocab_size)\n        self.prediction_layer_activation = torch.nn.Softmax(dim=2)\n\n    def forward(self,Y_padded_input_mini_batch,final_encoder_output,final_cell_state):\n\n        first_embedding_layer_out = self.first_embedding_layer(Y_padded_input_mini_batch)\n        decoder_lstm_layer_out, (final_decoder_lstm_layer_out, final_cell_state) = self.second_lstm_layer(first_embedding_layer_out,\n                                                                                                         (final_encoder_output,\n                                                                                                          final_cell_state))\n        prediction = self.prediction_layer_activation(self.prediction_layer(decoder_lstm_layer_out))\n        \n        return prediction, (final_decoder_lstm_layer_out, final_cell_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:45:15.839329Z","iopub.execute_input":"2025-08-29T08:45:15.839903Z","iopub.status.idle":"2025-08-29T08:45:15.845126Z","shell.execute_reply.started":"2025-08-29T08:45:15.839878Z","shell.execute_reply":"2025-08-29T08:45:15.844460Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class Seq2SeqEncDec(torch.nn.Module):\n\n    def __init__(self,src_lang_vocab_size,dst_lang_vocab_size,word_embedding_dim):\n        super(Seq2SeqEncDec,self).__init__()\n\n        self.encoder = Encoder(src_lang_vocab_size,word_embedding_dim)\n        self.decoder = Decoder(dst_lang_vocab_size,word_embedding_dim)\n\n    def forward(self,X_padded_mini_batch,Y_padded_input_mini_batch):\n\n        encoder_output, (final_encoder_output,final_cell_state) = self.encoder(X_padded_mini_batch)\n        y_hat_mini_batch = self.decoder(Y_padded_input_mini_batch,\n                                        final_encoder_output,final_cell_state)\n\n        return y_hat_mini_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:45:18.736381Z","iopub.execute_input":"2025-08-29T08:45:18.736933Z","iopub.status.idle":"2025-08-29T08:45:18.741288Z","shell.execute_reply.started":"2025-08-29T08:45:18.736911Z","shell.execute_reply":"2025-08-29T08:45:18.740462Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:47:53.484091Z","iopub.execute_input":"2025-08-29T08:47:53.484750Z","iopub.status.idle":"2025-08-29T08:47:53.554322Z","shell.execute_reply.started":"2025-08-29T08:47:53.484725Z","shell.execute_reply":"2025-08-29T08:47:53.553682Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"X_padded_train = X_padded[0:13000]\nY_padded_input_train = Y_padded_input[0:13000]\nY_padded_label_train = Y_padded_label[0:13000]\n\nX_padded_test = X_padded[13000:]\nY_padded_input_test = Y_padded_input[13000:]\nY_padded_label_test = Y_padded_label[13000:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:52:48.704932Z","iopub.execute_input":"2025-08-29T08:52:48.705232Z","iopub.status.idle":"2025-08-29T08:52:48.709643Z","shell.execute_reply.started":"2025-08-29T08:52:48.705211Z","shell.execute_reply":"2025-08-29T08:52:48.708954Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"network = Seq2SeqEncDec(len(Vs),len(Vd),128).to(device)\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\noptimizer = torch.optim.Adam(network.parameters())\nnum_epochs = 25\nmb_size = 65\n\nfor epoch in range(num_epochs):\n    for i in range(X_padded_train.shape[0]//mb_size):\n\n        X_train_mb = X_padded_train[i*mb_size:(i+1)*mb_size]\n        Y_input_mb = Y_padded_input_train[i*mb_size:(i+1)*mb_size]\n        Y_label_mb = Y_padded_label_train[i*mb_size:(i+1)*mb_size]\n\n        X_train_mb, Y_input_mb, Y_label_mb = X_train_mb.to(device), Y_input_mb.to(device), Y_label_mb.to(device)\n\n        y_hat_train_mb = network(X_train_mb,Y_input_mb)\n\n        loss_fn_value = loss_fn(y_hat_train_mb,Y_label_mb)\n\n        loss_fn_value.backward()\n        torch.nn.utils.clip_grad_norm_(network.parameters(),max_norm=1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n\n        print(\"Epoch # {}, Time Step # {}, Loss Value = {}\".format(epoch,i,loss_fn_value))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T09:38:49.219556Z","iopub.execute_input":"2025-08-29T09:38:49.219859Z","iopub.status.idle":"2025-08-29T09:38:52.605497Z","shell.execute_reply.started":"2025-08-29T09:38:49.219836Z","shell.execute_reply":"2025-08-29T09:38:52.604364Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2436329030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my_hat_train_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_input_mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss_fn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_train_mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_label_mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss_fn_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1296\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3495\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple"],"ename":"TypeError","evalue":"cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}